{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Import Library"],"metadata":{"id":"xRz9p11uFsHc"}},{"cell_type":"code","source":["import os\n","import csv\n","import re\n","import json\n","import pandas as pd"],"metadata":{"id":"Kd8H1jklF0k_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load Dataset"],"metadata":{"id":"picMakk7F45U"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A5hvmLg2EUXa","executionInfo":{"status":"ok","timestamp":1736171670340,"user_tz":-420,"elapsed":8434,"user":{"displayName":"Ki La","userId":"03033384605989319650"}},"outputId":"0398e1c0-bdff-4c5d-f666-224e6eca8e63"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.12.14)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"]}],"source":["!pip install gdown"]},{"cell_type":"code","source":["!gdown \"https://drive.google.com/uc?id=1rozvTivcopRIejyknzg_N-LRi8k1UNY9\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vsYQ4t_MFpVw","executionInfo":{"status":"ok","timestamp":1736171675089,"user_tz":-420,"elapsed":4754,"user":{"displayName":"Ki La","userId":"03033384605989319650"}},"outputId":"20e664ce-0df8-4783-c4fc-68fecd678d77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1rozvTivcopRIejyknzg_N-LRi8k1UNY9\n","To: /content/keywords.txt\n","\r  0% 0.00/3.92k [00:00<?, ?B/s]\r100% 3.92k/3.92k [00:00<00:00, 8.15MB/s]\n"]}]},{"cell_type":"code","source":["!gdown \"https://drive.google.com/uc?id=1cf4aqDvIBNTB6vVj6ADb3iSdsOJbH4-5\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x_V98S_IGJp_","executionInfo":{"status":"ok","timestamp":1736171680963,"user_tz":-420,"elapsed":5881,"user":{"displayName":"Ki La","userId":"03033384605989319650"}},"outputId":"93a7d5bc-65af-4028-931f-dc066522b4c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1cf4aqDvIBNTB6vVj6ADb3iSdsOJbH4-5\n","To: /content/putusan.zip\n","\r  0% 0.00/4.98M [00:00<?, ?B/s]\r100% 4.98M/4.98M [00:00<00:00, 242MB/s]\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"39RoIE6XGZqY","executionInfo":{"status":"ok","timestamp":1736171680964,"user_tz":-420,"elapsed":15,"user":{"displayName":"Ki La","userId":"03033384605989319650"}},"outputId":"fad558b7-a8f6-4678-f762-38f4e858f003"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["keywords.txt  putusan.zip  sample_data\n"]}]},{"cell_type":"code","source":["# Extraction ZIP to Folder\n","from zipfile import ZipFile\n","\n","# Path ke file ZIP\n","zip_file = \"/content/putusan.zip\"\n","output_folder = \"/content/putusan\"\n","\n","# Ekstrak ZIP\n","with ZipFile(zip_file, 'r') as zip_ref:\n","    zip_ref.extractall(output_folder)\n","\n","print(f\"File diekstrak ke {output_folder}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vT3tNl8gGyBc","executionInfo":{"status":"ok","timestamp":1736171680964,"user_tz":-420,"elapsed":10,"user":{"displayName":"Ki La","userId":"03033384605989319650"}},"outputId":"ad33392b-9829-47f0-a542-57fa3166c340"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["File diekstrak ke /content/putusan\n"]}]},{"cell_type":"markdown","source":["# Verdict Extraction"],"metadata":{"id":"Uduq4O4nHBPh"}},{"cell_type":"code","source":["# Load keywords from a file\n","def load_keywords_from_file(file_path):\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        keywords = json.load(file)\n","    return keywords\n","\n","# Extract \"No Putusan\"\n","def extract_no_putusan(content):\n","    pattern = r\"(Nomor\\s*[:\\-]?\\s*\\d+/[A-Za-z.]+/\\d+/[A-Za-z\\s\\-]{1,7})\"\n","    match = re.search(pattern, content)\n","    return match.group(1) if match else None\n","\n","# Extract \"Lembaga Peradilan\"\n","def extract_lembaga_peradilan(content):\n","    pattern = r\"(Pengadilan\\s*(Negeri|Agama|Tinggi)(\\s*di)?\\s*\\w+)(?!\\w)\"\n","    match = re.search(pattern, content)\n","    return match.group(1) if match else None\n","\n","# Extract data from content using keywords\n","def extract_data_from_content(content, keywords):\n","    extracted_texts = []\n","    extracted_ranges = []\n","\n","    for keyword in keywords:\n","        pattern = re.escape(keyword)\n","        match = re.search(pattern, content, re.IGNORECASE)\n","\n","        if match:\n","            start_index = match.start()\n","            end_index = content.find('\\n\\n', start_index)\n","            end_index = end_index if end_index != -1 else len(content)\n","\n","            overlaps = any(start <= start_index <= end or start <= end_index <= end for start, end in extracted_ranges)\n","            if overlaps:\n","                continue\n","\n","            extracted_paragraph = content[start_index:end_index].strip()\n","\n","            while extracted_paragraph.count('.') < 5:\n","                additional_end_index = content.find('\\n\\n', end_index + 2)\n","                additional_end_index = additional_end_index if additional_end_index != -1 else len(content)\n","                extracted_paragraph += content[end_index:additional_end_index].strip()\n","                end_index = additional_end_index\n","\n","            extracted_texts.append(extracted_paragraph)\n","            extracted_ranges.append((start_index, end_index))\n","\n","    consolidated_text = \"\\n\\n\".join(extracted_texts)\n","    return consolidated_text if consolidated_text else None\n","\n","# Extract paragraph related to 'wanprestasi'\n","def extract_wanprestasi_paragraph(content):\n","    pattern = r\"(Tergugat\\stelah\\smelakukan(?:perbuatan\\s)?wanprestasi.*?)(?:\\n\\n|\\Z)\"\n","    match = re.search(pattern, content)\n","    return match.group(1) if match else None\n","\n","def extract_data_from_file(file_path):\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        content = file.read()\n","\n","    extracted_data = {category: None for category in KEYWORDS.keys()}\n","\n","    extracted_data[\"No Putusan\"] = extract_no_putusan(content)\n","    extracted_data[\"Lembaga Peradilan\"] = extract_lembaga_peradilan(content)\n","    extracted_data[\"Perihal Gugatan\"] = extract_wanprestasi_paragraph(content)\n","    extracted_data[\"Identitas Terdakwa\"] = extract_data_from_content(content, KEYWORDS[\"Identitas Terdakwa\"])\n","\n","    for category, keywords in KEYWORDS.items():\n","        if category not in [\"No Putusan\", \"Lembaga Peradilan\", \"Perihal Gugatan\", \"Identitas Terdakwa\"]:\n","            extracted_data[category] = extract_data_from_content(content, keywords)\n","\n","    return extracted_data\n","\n","# Extract \"Penuntut Umum\" from descriptive text with clean formatting\n","def extract_penuntut_umum(logging_csv_path):\n","    logging_data = pd.read_csv(logging_csv_path, header=None)  # Assume no explicit column headers\n","    penuntut_umum_dict = {}\n","\n","    for index, row in logging_data.iterrows():\n","        full_text = row[0]  # Assuming all data is in the first column\n","        # Match the name and stop before \"Terdakwa\" if it exists\n","        match = re.search(r\"Penuntut Umum\\s*:\\s*([A-Za-z\\s,.\\-]+?)(?=\\s*Terdakwa|$)\", full_text)\n","        if match:\n","            penuntut_umum_name = match.group(1).strip()\n","            # Clean the name format\n","            penuntut_umum_name = re.sub(r\"\\s*,\\s*\", \", \", penuntut_umum_name)  # Ensure spacing after comma\n","            penuntut_umum_name = re.sub(r\"\\s*\\.\\s*\", \". \", penuntut_umum_name)  # Ensure spacing after period\n","            penuntut_umum_name = re.sub(r\"\\b(S\\.H|M\\.H|Ph\\.D|Dr)\\b\", lambda m: m.group(0).replace(\".\", \"\"), penuntut_umum_name)  # Remove dots from titles\n","        else:\n","            penuntut_umum_name = \"N/A\"\n","\n","        penuntut_umum_dict[index] = penuntut_umum_name\n","\n","    return penuntut_umum_dict\n","\n","# Extract \"Tanggal Register\" directly from the 'tanggal_register' column in Logging.csv\n","def extract_tanggal_register(logging_csv_path):\n","    logging_data = pd.read_csv(logging_csv_path)  # Assumes the CSV has column headers\n","\n","    tanggal_register_dict = {}\n","\n","    # Ensure the column name is correctly referenced\n","    if 'tanggal_register' not in logging_data.columns:\n","        raise ValueError(\"The column 'tanggal_register' was not found in the CSV file.\")\n","\n","    for index, row in logging_data.iterrows():\n","        tanggal_register = row['tanggal_register']  # Directly access the 'tanggal_register' column\n","        tanggal_register = tanggal_register if pd.notna(tanggal_register) else \"N/A\"\n","        tanggal_register_dict[index] = tanggal_register\n","\n","    return tanggal_register_dict\n","\n","# Extract \"Tanggal Putusan\" from the 'judul' column in Logging.csv (Assuming the title has a date)\n","# Extract \"Tanggal Putusan\" from the 'judul' column in Logging.csv (assuming the date is after the word 'Tanggal')\n","def extract_tanggal_putusan(logging_csv_path):\n","    logging_data = pd.read_csv(logging_csv_path)  # Assumes the CSV has column headers\n","\n","    tanggal_putusan_dict = {}\n","\n","    # Ensure the column name is correctly referenced\n","    if 'judul' not in logging_data.columns:\n","        raise ValueError(\"The column 'judul' was not found in the CSV file.\")\n","\n","    for index, row in logging_data.iterrows():\n","        # Extract the date from 'judul' after the word 'Tanggal'\n","        title = row['judul']\n","        # Match a date pattern following the word \"Tanggal\"\n","        match = re.search(r\"Tanggal\\s+(\\d{1,2}\\s+[A-Za-z]+\\s+\\d{4})\", title)\n","        if match:\n","            tanggal_putusan = match.group(1)  # Extracted date\n","        else:\n","            tanggal_putusan = \"N/A\"\n","\n","        tanggal_putusan_dict[index] = tanggal_putusan\n","\n","    return tanggal_putusan_dict\n","\n","# Clean illegal characters for Excel\n","def clean_illegal_characters(data):\n","    cleaned_data = {k: re.sub(r'[\\x00-\\x1F\\x7F]', ' ', str(v)) if v is not None else '' for k, v in data.items()}\n","    return cleaned_data\n","\n","# Save data to an Excel file\n","def save_to_excel(data, output_file):\n","    cleaned_data = {filename: clean_illegal_characters(file_data) for filename, file_data in data.items()}\n","    df = pd.DataFrame(cleaned_data).transpose()\n","    df = df.fillna(\"\")\n","    df.to_excel(output_file, index_label=\"File Name\")\n","\n","# Read files from a folder and extract data to Excel\n","def read_folder_and_extract_data(folder_path, logging_csv_path, output_file_path, exclude_files=None):\n","    if exclude_files is None:\n","        exclude_files = []\n","\n","    # Load data for Penuntut Umum, Tanggal Register, and Tanggal Putusan from logging CSV\n","    penuntut_umum_data = extract_penuntut_umum(logging_csv_path)\n","    tanggal_register_data = extract_tanggal_register(logging_csv_path)  # Extract Tanggal Register\n","    tanggal_putusan_data = extract_tanggal_putusan(logging_csv_path)  # Extract Tanggal Putusan\n","\n","    all_extracted_data = {}\n","\n","    # Iterate over files in the folder\n","    for idx, file_name in enumerate(os.listdir(folder_path)):\n","        if file_name in exclude_files:\n","            continue  # Skip excluded files\n","\n","        if file_name.endswith('.txt'):\n","            file_path = os.path.join(folder_path, file_name)\n","            extracted_data = extract_data_from_file(file_path)\n","\n","            # Add Penuntut Umum, Tanggal Register, and Tanggal Putusan data using index (make sure it matches the text index)\n","            extracted_data['Penuntut Umum'] = penuntut_umum_data.get(idx, \"N/A\")\n","            extracted_data['Tanggal Register'] = tanggal_register_data.get(idx, \"N/A\")\n","            extracted_data['Tanggal Putusan'] = tanggal_putusan_data.get(idx, \"N/A\")  # Add Tanggal Putusan\n","\n","            all_extracted_data[file_name] = extracted_data\n","\n","    # Save the extracted data to an Excel file\n","    save_to_excel(all_extracted_data, output_file_path)\n","\n","# Specify the file to exclude\n","exclude_files = ['_2025-01-05.txt']\n","\n","# Execute the extraction process\n","KEYWORDS = load_keywords_from_file('keywords.txt')\n","source_folder = 'putusan/'\n","logging_csv = 'putusan/Logging.csv'\n","destination_file = 'Data.xlsx'\n","read_folder_and_extract_data(source_folder, logging_csv, destination_file, exclude_files=exclude_files)"],"metadata":{"id":"8DBYI6fbHOWa"},"execution_count":null,"outputs":[]}]}